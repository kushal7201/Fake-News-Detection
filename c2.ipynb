{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k7adi\\AppData\\Local\\Temp\\ipykernel_20016\\3649794072.py:29: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_data_set.replace(stances, inplace=True)\n",
      "C:\\Users\\k7adi\\AppData\\Local\\Temp\\ipykernel_20016\\3649794072.py:59: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_data_set.replace(stances, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2135\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle as pkl\n",
    "\n",
    "# Constants\n",
    "PATH = './'\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Load the train data\n",
    "def load_train_data():\n",
    "    train_bodies = pd.read_csv(PATH + \"train_bodies.csv\", encoding='utf-8')\n",
    "    train_headlines = pd.read_csv(PATH + \"train_stances.csv\", encoding='utf-8')\n",
    "    train_data_set = pd.merge(train_bodies, train_headlines, how='left', on='Body ID')\n",
    "    stances = {\n",
    "        'Stance': {\n",
    "          'agree': 0,\n",
    "          'disagree': 1,\n",
    "          'discuss': 2,\n",
    "          'unrelated': 3,\n",
    "        }\n",
    "    }\n",
    "    train_data_set.replace(stances, inplace=True)\n",
    "    \n",
    "    # Remove rows with missing 'articleBody' or 'Headline'\n",
    "    train_data_set.dropna(subset=['articleBody', 'Headline'], inplace=True)\n",
    "    \n",
    "    # Sampling\n",
    "    data_length = 8909\n",
    "    unrelated_resampled = resample(train_data_set.loc[train_data_set['Stance'] == 3], replace=False, n_samples=data_length, random_state=RANDOM_SEED)\n",
    "    discuss_resampled = resample(train_data_set.loc[train_data_set['Stance'] == 2], replace=False, n_samples=data_length, random_state=RANDOM_SEED)\n",
    "    agree_resampled = resample(train_data_set.loc[train_data_set['Stance'] == 0], replace=True, n_samples=data_length, random_state=RANDOM_SEED)\n",
    "    disagree_resampled = resample(train_data_set.loc[train_data_set['Stance'] == 1], replace=True, n_samples=data_length, random_state=RANDOM_SEED)\n",
    "  \n",
    "    all_resampled = [unrelated_resampled, discuss_resampled, agree_resampled, disagree_resampled]\n",
    "    result = pd.concat(all_resampled).sample(frac=1)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Load the test data\n",
    "def load_test_data():     \n",
    "    test_bodies = pd.read_csv(PATH + \"competition_test_bodies.csv\", encoding='utf-8')\n",
    "    test_headlines = pd.read_csv(PATH + 'competition_test_stances.csv', encoding='utf-8')\n",
    "    test_data_set = pd.merge(test_bodies, test_headlines, how='left', on='Body ID')\n",
    "    stances = {\n",
    "        'Stance': {\n",
    "          'agree': 0,\n",
    "          'disagree': 1,\n",
    "          'discuss': 2,\n",
    "          'unrelated': 3,\n",
    "        }\n",
    "    }\n",
    "    test_data_set.replace(stances, inplace=True)\n",
    "    \n",
    "    # Remove rows with missing 'articleBody' or 'Headline'\n",
    "    test_data_set.dropna(subset=['articleBody', 'Headline'], inplace=True)\n",
    "    \n",
    "    return test_data_set \n",
    "\n",
    "# Prepare the data for Passive-Aggressive Classifier\n",
    "def prepare_data(data_set, vectorizer=None):\n",
    "    X = data_set['articleBody'].fillna('') + \" \" + data_set['Headline'].fillna('')\n",
    "    y = data_set['Stance']\n",
    "    \n",
    "    # Convert text to numerical features using TF-IDF\n",
    "    if vectorizer is None:\n",
    "        vectorizer = TfidfVectorizer(stop_words='english', lowercase=True)\n",
    "        X_features = vectorizer.fit_transform(X)\n",
    "        # Save the vectorizer\n",
    "        with open('vectorizer.pkl', 'wb') as handle:\n",
    "            pkl.dump(vectorizer, handle, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    else:\n",
    "        X_features = vectorizer.transform(X)\n",
    "    \n",
    "    return X_features, y, vectorizer\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_data = load_train_data()\n",
    "    test_data = load_test_data()\n",
    "    \n",
    "    # Prepare training data\n",
    "    X_train, y_train, vectorizer = prepare_data(train_data)\n",
    "    \n",
    "    # Prepare test data with the same vectorizer\n",
    "    X_test, y_test, _ = prepare_data(test_data, vectorizer)\n",
    "    \n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "    y_test_encoded = label_encoder.transform(y_test)\n",
    "    \n",
    "    # Train the Passive-Aggressive Classifier\n",
    "    pac = PassiveAggressiveClassifier(max_iter=100000, random_state=RANDOM_SEED)\n",
    "    pac.fit(X_train, y_train_encoded)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = pac.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Save the model\n",
    "    with open('pac_model.pkl', 'wb') as handle:\n",
    "        pkl.dump(pac, handle, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    # Save the label encoder\n",
    "    with open('label_encoder.pkl', 'wb') as handle:\n",
    "        pkl.dump(label_encoder, handle, protocol=pkl.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
